{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import hashlib\n",
    "import base64\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.dammit import EncodingDetector\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from annoy import AnnoyIndex\n",
    "\n",
    "# from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(html_table, tag=['th', 'tr', 'td']):\n",
    "    table_value = []\n",
    "\n",
    "\n",
    "    # for my_table in tables:\n",
    "\n",
    "    # You can find children with multiple tags by passing a list of strings\n",
    "    rows = html_table.findChildren(tag)\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.findChildren(tag)\n",
    "        for cell in cells:\n",
    "            value = cell.string\n",
    "            if value:\n",
    "                table_value.append(value.strip())\n",
    "                # print(\"The value in this cell is %s\" % value)\n",
    "            else:\n",
    "                table_value.append(\"None\")\n",
    "    return dict(zip(table_value[::2], table_value[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(url):\n",
    "    \n",
    "    # get the html file\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    if page.status_code == 200:\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # get all the tables\n",
    "        tables = soup.findChildren('table')\n",
    "\n",
    "        # only the first 4 tables are useful\n",
    "        tables = tables[:4]\n",
    "\n",
    "\n",
    "        # UPPER LEFT TABLE\n",
    "        table_ul = get_tables(tables[0])\n",
    "\n",
    "        # UPPER RIGHT TABLE\n",
    "        rows_html = tables[1].findAll(\"span\", {\"class\": lambda x: x and x.startswith(\"rating\")})\n",
    "        rows = [x.get_text() for x in rows_html]\n",
    "        table_ur = dict(zip(rows[::2], rows[1::2]))\n",
    "\n",
    "#         # BUTTOM TABLES\n",
    "\n",
    "#         table_b = {}\n",
    "#         for t in tables[2:]:\n",
    "#             l = get_tables(t, ['td', 'p', 'tr'])\n",
    "#             table_b.update(l)\n",
    "\n",
    "\n",
    "        all_items = {**table_ul, **table_ur}\n",
    "    \n",
    "    else:\n",
    "        print(page.status_code)\n",
    "\n",
    "\n",
    "    return all_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(input_text):\n",
    "    \n",
    "    year = re.findall('[0-9]{4}', input_text)\n",
    "    \n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashme(x):\n",
    "    return base64.b64encode(hashlib.sha1(x).digest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_boards(gender):\n",
    "    \n",
    "#     browser = webdriver.Chrome()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(\"https://thegoodride.com/snowboard-reviews/?{}=1\".format(gender))\n",
    "    time.sleep(1)\n",
    "\n",
    "    button = driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/form/div[1]/div[42]/a')\n",
    "    driver.execute_script(\"arguments[0].click();\", button)\n",
    "    time.sleep(100)\n",
    "    html = driver.page_source\n",
    "\n",
    "#     driver.close()\n",
    "    \n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    \"\"\"Create an S3 bucket in a specified region\n",
    "\n",
    "    If a region is not specified, the bucket is created in the S3 default\n",
    "    region (us-east-1).\n",
    "\n",
    "    :param bucket_name: Bucket to create\n",
    "    :param region: String region to create bucket in, e.g., 'us-west-2'\n",
    "    :return: True if bucket created, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Create bucket\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client = boto3.client('s3')\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            s3_client = boto3.client('s3', region_name=region)\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration=location)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "#     try:\n",
    "    response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "#     exceptions ClientError as e:\n",
    "#         logging.error(e)\n",
    "#         return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime('%Y%m%d')\n",
    "genders = ['mens', 'womens']\n",
    "\n",
    "for g in genders:\n",
    "    \n",
    "    raw_html = get_all_boards(g)\n",
    "    \n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    rows_html = soup.findAll(\"div\", {\"class\": \"board-reviews animate\"})\n",
    "\n",
    "    all_boards = []\n",
    "        \n",
    "    for board in rows_html:\n",
    "        board_name = board.select('h4')[0].text.strip()\n",
    "        review_url = board.select('a', href=True)[0]['href']\n",
    "        all_boards.append([board_name, review_url])\n",
    "        \n",
    "    df_url = pd.DataFrame(all_boards, columns=['board_name', 'url'])\n",
    "    print(df_url.shape)\n",
    "\n",
    "    df_url.to_csv('../data/all_{}_boards.csv'.format(g), index=False)\n",
    "    \n",
    "    rating_list = []\n",
    "    for url in tqdm(df_url['url']):\n",
    "        d = parse_page(url)\n",
    "        assert len(d) == 18\n",
    "        rating_list.append(d)\n",
    "        time.sleep(.1)\n",
    "        \n",
    "    df_rating = pd.DataFrame(rating_list)\n",
    "    df_final = pd.concat([df_url, df_rating], axis=1)\n",
    "    df_final['year'] = df_final['url'].apply(get_date)\n",
    "    df_final['gender'] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['id'] = df_final['url'].astype(str).str.encode('UTF-8').apply(hashme)\n",
    "df_final['id'] = df_final['id'].apply(lambda x: x.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../data/all_boards_board_{}.csv'.format(today), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bucket(\"snowboard-finder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('../data/all_boards_board_{}.csv'.format(today), \n",
    "            \"snowboard-finder\",\n",
    "            \"all_boards_{}.csv\".format(today))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Board Recomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('../data/all_boards_board_{}.csv'.format(today))\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_cols = ['Riding Style', 'Riding Level', 'Shape', 'Camber Profile',\n",
    "       'Stance', 'Approx. Weight', 'Powder', 'Turning Experience', 'Carving',\n",
    "       'Speed', 'Uneven Terrain', 'Switch', 'Jumps', 'Jibbing', 'Pipe', 'gender']\n",
    "\n",
    "meta_cols = ['board_name', 'url', 'Overall Rating',\n",
    "             'Fits Boot size (US)', 'Manufactured in', 'year', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final[filter_cols].get_dummies()\n",
    "df_final_dummies = pd.get_dummies(df_final, columns=filter_cols)\n",
    "df_final_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANNOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = df_final_dummies.shape[1] - len(meta_cols)\n",
    "\n",
    "# a = AnnoyIndex(f, 'angular')\n",
    "\n",
    "# for idx, row in df_final_dummies.drop(labels=meta_cols, axis=1).iterrows():\n",
    "#      a.add_item(idx, row.to_list())\n",
    "# #     print(row.values)\n",
    "\n",
    "# a.build(10)\n",
    "# a.save('../model/annoy_all_angular_20201223.ann')\n",
    "\n",
    "# upload_file('../model/annoy_all_angular_20201223.ann', \"snowboard-finder\", \"/model/annoy_all_angular_20201223.ann\")\n",
    "\n",
    "# u = AnnoyIndex(f, 'angular')\n",
    "# u.load('../model/annoy_all_angular_20201223.ann') # super fast, will just mmap the file\n",
    "\n",
    "# print(u.get_nns_by_item(173, 20)) # will find the 1000 nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "def distance_function(r):\n",
    "    dists = pdist(r, 'jaccard')\n",
    "    \n",
    "    return pd.DataFrame(squareform(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist = distance_function(df_final_dummies.drop(labels=meta_cols, axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add similar boards to each rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_boards = []\n",
    "for idx, row in df_dist.iterrows():\n",
    "    \n",
    "    target = df_dist.iloc[:, idx].nsmallest(10)\n",
    "    df_target = pd.merge(df_final['id'][target.index].reset_index(), target.reset_index(), on='index')\n",
    "    df_target.columns = ['index', 'id', 'sim_value']\n",
    "    sim_dict = pd.Series(df_target['sim_value'].values, index=df_target['id']).to_dict()\n",
    "    sim_boards.append(sim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['similar_boards'] = sim_boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../data/all_boards_similarity_20201222.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('../data/all_boards_similarity_20201222.csv',\n",
    "            \"snowboard-finder\",\n",
    "            \"all_boards_similarity_20201222.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "ddb = boto3.resource('dynamodb')\n",
    "table = ddb.Table('SnowboardDatabase')\n",
    "attrs = table.attribute_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
